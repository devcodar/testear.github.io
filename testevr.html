<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Detecção e Análise Ergonômica</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      background: #f4f4f9;
      margin: 0;
      padding: 0;
    }

    video, canvas {
      width: 90%;
      max-width: 640px;
      margin: 10px auto;
      border-radius: 10px;
      display: block;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    }

    #metrics, #logContainer {
      width: 90%;
      max-width: 640px;
      background: #f0f0f0;
      border-radius: 20px;
      padding: 10px;
      margin: 10px auto;
      max-height: 200px;
      overflow-y: auto;
      text-align: left;
    }

    #logContainer {
      background: #222;
      color: #0f0;
      font-family: monospace;
    }

    #controls button {
      background: #007bff;
      color: white;
      border: none;
      padding: 10px;
      font-size: 14px;
      margin: 5px;
      border-radius: 8px;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <h1>Detecção e Análise Ergonômica</h1>
  <video id="videoElement" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
  <div id="metrics">
    <h2>Métricas</h2>
    <ul id="metricsList"></ul>
  </div>

  <div id="logContainer">
    <h2>Log</h2>
    <ul id="logList"></ul>
  </div>

  <div id="controls">
    <button id="switchCamera">Trocar Câmera</button>
    <button id="pauseCapture">Pausar Captura</button>
    <button id="startVR">Ativar VR</button>
    <button id="downloadReport">Baixar Relatório</button>
  </div>

  <script>
    const videoElement = document.getElementById("videoElement");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const metricsList = document.getElementById("metricsList");
    const logList = document.getElementById("logList");
    const switchCameraBtn = document.getElementById("switchCamera");
    const pauseCaptureBtn = document.getElementById("pauseCapture");
    const startVRBtn = document.getElementById("startVR");
    const downloadReportBtn = document.getElementById("downloadReport");

    let cocoModel, poseModel;
    let currentStream;
    let usingFrontCamera = true;
    let isPaused = false;
    const detectionCount = {};
    const FOV = 60; // Campo de visão da câmera para conversão em escala real

    async function setupCamera(facingMode = "user") {
      if (currentStream) {
        currentStream.getTracks().forEach((track) => track.stop());
      }
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode } });
      videoElement.srcObject = stream;
      currentStream = stream;
    }

    async function loadModels() {
      cocoModel = await cocoSsd.load();
      poseModel = await posenet.load();
    }

    function calculateDistance(p1, p2) {
      return Math.sqrt(Math.pow(p1.x - p2.x, 2) + Math.pow(p1.y - p2.y, 2));
    }

    function convertToRealScale(pixelValue) {
      const screenWidth = canvas.width;
      const estimatedDistance = 1.5; // Distância média da câmera (em metros)
      const realScaleFactor = (2 * estimatedDistance * Math.tan((FOV / 2) * (Math.PI / 180))) / screenWidth;
      return (pixelValue * realScaleFactor * 100).toFixed(2); // Retorna em cm
    }

    function calculateAreaInCm2(width, height) {
      const realWidth = convertToRealScale(width);
      const realHeight = convertToRealScale(height);
      return (realWidth * realHeight).toFixed(2); // Retorna em cm²
    }

    function logMessage(message) {
      const logItem = document.createElement("li");
      logItem.textContent = message;
      logList.appendChild(logItem);
      logList.parentElement.scrollTop = logList.parentElement.scrollHeight;
    }

    function renderObjects(objects) {
      objects.forEach((obj) => {
        const [x, y, width, height] = obj.bbox;
        const areaInCm2 = calculateAreaInCm2(width, height);

        detectionCount[obj.class] = (detectionCount[obj.class] || 0) + 1;

        ctx.strokeStyle = "blue";
        ctx.lineWidth = 2;
        ctx.strokeRect(x, y, width, height);
        ctx.fillStyle = "blue";
        ctx.font = "16px Arial";
        ctx.fillText(
          `${obj.class} (${(obj.score * 100).toFixed(1)}%)`,
          x,
          y > 10 ? y - 5 : 10
        );
        ctx.fillText(`Área: ${areaInCm2} cm²`, x, y + 15);

        logMessage(
          `${obj.class} detectado (${detectionCount[obj.class]}x). Área: ${areaInCm2} cm²`
        );
      });
    }

    function checkErgonomicStandards(pose) {
      const leftShoulder = pose.keypoints[5].position;
      const rightShoulder = pose.keypoints[6].position;
      const leftHip = pose.keypoints[11].position;
      const leftWrist = pose.keypoints[9].position;

      const shoulderWidth = convertToRealScale(calculateDistance(leftShoulder, rightShoulder));
      const torsoHeight = convertToRealScale(calculateDistance(leftShoulder, leftHip));
      const armLength = convertToRealScale(calculateDistance(leftShoulder, leftWrist));

      const shoulderArea = calculateAreaInCm2(shoulderWidth, 5); // Considerando 5cm de espessura média
      const torsoArea = calculateAreaInCm2(torsoHeight, 20); // Considerando 20cm de largura média

      logMessage(`Largura dos ombros: ${shoulderWidth} cm - Área: ${shoulderArea} cm²`);
      logMessage(`Altura do tronco: ${torsoHeight} cm - Área: ${torsoArea} cm²`);
      logMessage(`Comprimento do braço: ${armLength} cm`);
    }

    async function detectLoop() {
      if (isPaused) return;

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

      const objects = await cocoModel.detect(videoElement);
      renderObjects(objects);

      const pose = await poseModel.estimateSinglePose(videoElement);
      checkErgonomicStandards(pose);

      requestAnimationFrame(detectLoop);
    }

    switchCameraBtn.addEventListener("click", async () => {
      usingFrontCamera = !usingFrontCamera;
      await setupCamera(usingFrontCamera ? "user" : "environment");
    });

    pauseCaptureBtn.addEventListener("click", () => {
      isPaused = !isPaused;
      pauseCaptureBtn.textContent = isPaused ? "Retomar Captura" : "Pausar Captura";
      if (!isPaused) detectLoop();
    });

    startVRBtn.addEventListener("click", async () => {
      alert("Modo VR ativado! (Simulação)");
    });

    downloadReportBtn.addEventListener("click", () => {
      const report = { timestamp: new Date().toISOString(), metrics: metricsList.innerText };
      const blob = new Blob([JSON.stringify(report, null, 2)], { type: "application/json" });
      const link = document.createElement("a");
      link.href = URL.createObjectURL(blob);
      link.download = "ergonomic_report.json";
      link.click();
    });

    async function init() {
      canvas.width = 640;
      canvas.height = 480;

      await setupCamera();
      await loadModels();
      detectLoop();
    }

    init();
  </script>
</body>
</html>