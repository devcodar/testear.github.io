<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Identificação de Objetos com COCO</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 0;
    }
    video, canvas {
      display: block;
      margin: 20px auto;
      border: 1px solid #ccc;
    }
    #status {
      font-size: 18px;
      color: #333;
    }
    #metrics {
      margin-top: 10px;
      font-size: 16px;
      color: #555;
      text-align: left;
      max-width: 640px;
      margin-left: auto;
      margin-right: auto;
    }
    #switchCamera {
      margin: 10px;
      padding: 10px 20px;
      font-size: 16px;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <h1>Identificação de Objetos - COCO Dataset</h1>
  <video id="videoElement" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
  <p id="status">Carregando modelo...</p>
  <div id="metrics">
    <h2>Métricas de Detecção</h2>
    <ul id="metricsList"></ul>
  </div>
  <button id="switchCamera">Trocar Câmera</button>

  <script>
    const videoElement = document.getElementById('videoElement');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const metricsList = document.getElementById('metricsList');
    const switchCameraBtn = document.getElementById('switchCamera');

    let model;
    let currentStream; // Stream atual
    let usingFrontCamera = true; // Flag para alternar entre câmera frontal e traseira
    const heatmap = []; // Mapa de calor para detecções
    const objectMetrics = {}; // Métricas por classe de objeto

    // Configurar e acessar a câmera
    async function setupCamera(facingMode = "user") {
      // Interrompe o stream atual, se existir
      if (currentStream) {
        currentStream.getTracks().forEach(track => track.stop());
      }

      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode },
        });
        videoElement.srcObject = stream;
        currentStream = stream;

        return new Promise((resolve) => {
          videoElement.onloadedmetadata = () => {
            videoElement.play();
            resolve();
          };
        });
      } catch (error) {
        console.error("Erro ao acessar a câmera:", error);
        alert("Não foi possível acessar a câmera. Verifique as permissões do navegador.");
      }
    }

    // Carregar o modelo COCO-SSD
    async function loadModel() {
      model = await cocoSsd.load();
      document.getElementById('status').innerText = 'Modelo carregado!';
    }

    // Atualizar as métricas
    function updateMetrics(predictions) {
      predictions.forEach(prediction => {
        const { class: className, bbox } = prediction;

        // Contar a quantidade de vezes que cada classe é detectada
        if (!objectMetrics[className]) {
          objectMetrics[className] = { count: 0, sizes: [] };
        }
        objectMetrics[className].count += 1;

        // Armazenar tamanhos dos objetos detectados
        const size = bbox[2] * bbox[3]; // Largura * Altura
        objectMetrics[className].sizes.push(size);
      });

      // Atualizar lista de métricas na tela
      metricsList.innerHTML = "";
      for (const [className, data] of Object.entries(objectMetrics)) {
        const averageSize = data.sizes.reduce((a, b) => a + b, 0) / data.sizes.length;
        const listItem = document.createElement("li");
        listItem.textContent = `Classe: ${className}, Detecções: ${data.count}, Tamanho médio: ${averageSize.toFixed(2)} pixels²`;
        metricsList.appendChild(listItem);
      }
    }

    // Detectar objetos no vídeo
    async function detectObjects() {
      if (!model) return;

      canvas.width = videoElement.videoWidth;
      canvas.height = videoElement.videoHeight;

      const predictions = await model.detect(videoElement);

      // Limpar o canvas
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // Atualizar métricas
      updateMetrics(predictions);

      // Renderizar bounding boxes e rótulos
      predictions.forEach((prediction) => {
        const [x, y, width, height] = prediction.bbox;
        const text = `${prediction.class} (${Math.round(prediction.score * 100)}%)`;

        // Desenhar a caixa delimitadora
        ctx.beginPath();
        ctx.rect(x, y, width, height);
        ctx.lineWidth = 2;
        ctx.strokeStyle = 'green';
        ctx.stroke();

        // Adicionar o rótulo
        ctx.fillStyle = 'green';
        ctx.fillText(text, x, y > 10 ? y - 5 : 10);
      });

      // Continuar detectando no próximo frame
      requestAnimationFrame(detectObjects);
    }

    // Trocar entre câmera frontal e traseira
    switchCameraBtn.addEventListener('click', async () => {
      usingFrontCamera = !usingFrontCamera; // Alterna entre as câmeras
      const facingMode = usingFrontCamera ? "user" : "environment";
      await setupCamera(facingMode); // Configura a câmera com o novo facingMode
      detectObjects(); // Reinicia a detecção com o novo feed
    });

    // Inicializar o sistema
    async function init() {
      await setupCamera(); // Inicializa com a câmera frontal
      await loadModel();
      detectObjects();
    }

    init();
  </script>
</body>
</html>