<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Detecção de Objetos e Poses</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      text-align: center;
      background: #f4f4f9;
      color: #333;
    }

    h1 {
      margin-top: 20px;
      font-size: 2rem;
    }

    video, canvas {
      width: 90%;
      max-width: 640px;
      margin: 20px auto;
      border-radius: 10px;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    }
  </style>
</head>
<body>
  <h1>Detecção de Objetos e Poses em Tempo Real</h1>
  <video id="videoElement" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
  <p id="status">Carregando modelos...</p>

  <script>
    const videoElement = document.getElementById("videoElement");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const statusElement = document.getElementById("status");

    let cocoModel, poseModel;

    // Configuração da câmera
    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user" },
      });
      videoElement.srcObject = stream;

      await new Promise((resolve) => {
        videoElement.onloadedmetadata = resolve;
      });
    }

    // Carregar os modelos COCO-SSD e PoseNet
    async function loadModels() {
      statusElement.textContent = "Carregando modelos...";
      cocoModel = await cocoSsd.load();
      poseModel = await posenet.load();
      statusElement.textContent = "Modelos carregados! Iniciando detecção...";
    }

    // Detectar poses e objetos
    async function detect() {
      // Limpar o canvas
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // Desenhar o vídeo no canvas
      ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

      // Detecção de objetos
      const objects = await cocoModel.detect(videoElement);
      renderObjects(objects);

      // Detecção de poses
      const pose = await poseModel.estimateSinglePose(videoElement, { flipHorizontal: false });
      renderPose(pose);

      // Loop contínuo
      requestAnimationFrame(detect);
    }

    // Renderizar objetos detectados
    function renderObjects(objects) {
      objects.forEach((obj) => {
        const [x, y, width, height] = obj.bbox;
        ctx.strokeStyle = "green";
        ctx.lineWidth = 2;
        ctx.strokeRect(x, y, width, height);

        ctx.fillStyle = "green";
        ctx.font = "16px Arial";
        ctx.fillText(`${obj.class} (${(obj.score * 100).toFixed(1)}%)`, x, y > 10 ? y - 5 : 10);
      });
    }

    // Renderizar pose detectada
    function renderPose(pose) {
      pose.keypoints.forEach((keypoint) => {
        if (keypoint.score > 0.5) {
          ctx.beginPath();
          ctx.arc(keypoint.position.x, keypoint.position.y, 5, 0, 2 * Math.PI);
          ctx.fillStyle = "red";
          ctx.fill();
        }
      });

      // Conexões entre pontos (esqueleto)
      const adjacentKeyPoints = posenet.getAdjacentKeyPoints(pose.keypoints, 0.5);
      adjacentKeyPoints.forEach(([from, to]) => {
        ctx.beginPath();
        ctx.moveTo(from.position.x, from.position.y);
        ctx.lineTo(to.position.x, to.position.y);
        ctx.lineWidth = 2;
        ctx.strokeStyle = "blue";
        ctx.stroke();
      });
    }

    // Inicialização
    async function init() {
      canvas.width = 640; // Largura do canvas
      canvas.height = 480; // Altura do canvas

      await setupCamera();
      await loadModels();
      detect();
    }

    init().catch((err) => {
      console.error(err);
      statusElement.textContent = `Erro: ${err.message}`;
    });
  </script>
</body>
</html>